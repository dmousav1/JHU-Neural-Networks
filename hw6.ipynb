{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1 + 2. This is Activation of the Hidden Layer: [0.75026011 0.75026011]\n",
      "Question 3. This is the Activation of the Output Layer: 0.6626741680915721\n",
      "Question 4 + 5. Here are output weights: [0.20425622 0.70425622]\n",
      "Question 6. Here are hidden weights: [[0.80024581 0.50084753]\n",
      " [0.10073743 0.20254259]]\n",
      "This is Question 6: 0.0008475294248857512\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function: Sigmoid and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Inputs\n",
    "x1 = 1\n",
    "x2 = 3\n",
    "inputs = np.array([x1, x2])\n",
    "\n",
    "# Target output\n",
    "target_output = 0.95\n",
    "\n",
    "# Learning rate (eta)\n",
    "eta = 0.1\n",
    "\n",
    "# Initial weights based on the diagram\n",
    "# weights between input layer and hidden layer\n",
    "w11 = 0.8\n",
    "w12 = 0.5\n",
    "w21 = 0.1\n",
    "w22 = 0.2\n",
    "\n",
    "# weights between hidden layer and output layer\n",
    "w31 = 0.2\n",
    "w32 = 0.7\n",
    "\n",
    "# Organize the weights into numpy arrays for simplicity\n",
    "hidden_weights = np.array([[w11, w12], [w21, w22]])  # shape (2, 2)\n",
    "output_weights = np.array([w31, w32])  # shape (2,)\n",
    "\n",
    "# Number of iterations for FFBP\n",
    "iterations = 1\n",
    "\n",
    "# Feed-forward and backpropagation (FFBP)\n",
    "for i in range(iterations):\n",
    "    # ---- Feed-forward step ----\n",
    "    # Input layer -> Hidden layer\n",
    "    activity_hidden = np.dot(inputs, hidden_weights)  # weighted sum for hidden layer\n",
    "    activation_hidden = sigmoid(activity_hidden)  # apply sigmoid activation for hidden layer\n",
    "    print(f\"Question 1 + 2. This is Activation of the Hidden Layer: {activation_hidden}\")\n",
    "\n",
    "    # Hidden layer -> Output layer\n",
    "    activity_output = np.dot(activation_hidden, output_weights)  # weighted sum for output layer\n",
    "    activation_output = sigmoid(activity_output)  # apply sigmoid activation for output layer\n",
    "    print(f\"Question 3. This is the Activation of the Output Layer: {activation_output}\")\n",
    "\n",
    "    # Calculate error at the output\n",
    "    error_output = activation_output - target_output\n",
    "\n",
    "    # ---- Backpropagation step ----\n",
    "    # Calculate delta for output layer\n",
    "    delta_output = error_output * activation_output * (1 - activation_output)\n",
    "\n",
    "    # Update weights between hidden and output layers\n",
    "    output_weights -= eta * delta_output * activation_output\n",
    "    print(f\"Question 4 + 5. Here are output weights: {output_weights}\")\n",
    "\n",
    "    # Calculate delta for hidden layer\n",
    "    delta_hidden = delta_output * output_weights * activation_hidden * (1 - activation_hidden)\n",
    "\n",
    "    # Update weights between input and hidden layers\n",
    "    hidden_weights -= eta * np.outer(inputs, delta_hidden)\n",
    "    print(f\"Question 6. Here are hidden weights: {hidden_weights}\")\n",
    "    print(f\"This is Question 6: {hidden_weights[0, 1] - w12}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
